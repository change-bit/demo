# 楪祈人格知识库问答系统 (demo版)

# 一、项目概述

基于inori-DeepSeek1.5B本地大模型搭建纯离线RAG知识库问答系统，仅调用嵌入模型API完成文本向量化（也可本地下载开源模型），其余全流程本地化运行；加载本地文档构建向量知识库，支持语义检索+知识库精准问答，无检索结果时自动切换原生闲聊模式；inori-DeepSeek1.5B本身基于deepseek微调，采用300条私有数据集训练，赋予了模型独特的“襟祈”人格设定与自我认知，并优化了特定场景下的情感表达与对话风格。

# 二、项目关键问题排查与修复

以下是构建项目时所遇到的问题及解决方法：

问题描述1 本地模型加载与框架提供接口不适配

原因 LlamaIndex 检索框架原生接口默认适配云端大模型 / OpenAI 类模型，本地 inori-DeepSeek1.5B 模型的加载方式、推理逻辑、输入输出格式，与框架原生的 LLM 调用接口完全不兼容，直接调用会出现接口调用失败、模型推理无输出、格式报错等问题。

解决方案自定义实现CustomDeepSeekLLM类，继承LlamaIndex的基础LLM抽象类，重写complete、stream Complete核心接口方法，将本地模型的加载、Tokenizer编码、推理生成、结果解码等逻辑，完全封装到自定义类中，手动完成本地模型与LlamaIndex框架的接口适配，实现框架对本地模型的无缝调用。

问题描述2无论输入任何和知识库相关的问题，均检索不到文档内容，模型无知识库支撑，回答内容混乱、答非所问。

原因配置的相似度过滤阈值similarity_cutoff=0.6过高，中文文本的Embedding相似度分数普遍偏低，绝大多数有效文档的相似度在  $0.4\sim 0.55$  区间，阈值0.6会一刀切过滤所有文档。

解决方案 简化检索流程，设置similarity_cutoff=0.4无多余过滤环节，确保检索必有结果

问题描述3检索到文档后，模型未基于知识库内容回答，反而编造信息、输出无关内容，或陷入闲聊式回复，违背RAG核心需求。

原因 本地小模型指令遵循能力弱，无强约束 Prompt 时，优先调用自身训练知识而非检索到的文档，且复杂 refine 迭代优化方案超出模型性能范围。

解决方案 放弃 refine 方案，设计强约束 Prompt 模板，强制模型仅基于检索到的文档内容回答，禁止编造信息、添加无关内容，精准提炼文档答案，抑制幻觉。并设计双模式 Prompt 逻辑，有检索结果时强制基于文档回答，无检索结果时允许模型自由回复，保留原生闲聊能力与人设，无需依赖 refine 等复杂策略。

问题描述4模型回答重复、随机性过高，输出内容不一致

原因模型推理参数配置不合理，温度系数偏高导致随机性强，重复惩罚系数偏低，本地模型无足够性能平衡生成效果与精准度。

解決決議方案預案優勢優化推薦理論參數數值，設置temperature=0.25、repetition_penalty=1.1、top_p=0.85，降低生成随机性，抑制重复内容，保证回答精准简洁。
